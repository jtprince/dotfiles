
# show all columns
pd.set_option('display.max_columns', None)

# show all rows
pd.set_option('display.max_rows', None)

# stack data frames on top of one another
pd.concat([df1, df2, ...], ignore_index=True)

# groupby

Make a new, temporary index column.

## group by 'X' column
groups = df.groupby("X")

for name, group in groups:
    ...

# value_counts
df['foo'].value_counts(dropna=False)


# Fill in missing values from other columns

## with boolean selection

df.loc[df["foo"].isna()==True, "foo"] = df["bar"]

## with fillna

df["foo"].fillna(df["Player"], inplace=True)


## explode some arrays into the columns

df.explode(['col2', 'col3'], ignore_index=True)
```
# initial
col0      col1        col2        col3
1       aa          [1,2,3]     [1.1,2.2,3.3]
2       bb          [4,5,6]     [4.4,5.5,6.6]
3       cc          [7,8,9]     [7.7,8.8,9.9]
3       cc          [7,8,9]     [7.7,8.8,9.9]

# desired
id      col1        col2        col3
1       aa          1           1.1
1       aa          2           2.2
1       aa          3           3.3
2       bb          4           4.4
2       bb          5           5.5
2       bb          6           6.6
3       cc          ...         ...
```

# aggregate into a named column

df_filtered.groupby("whatever").agg(<NEW_COLUMN_NAME>=('<col_to_agg_on>', '<the_func>'))

#### example
df_filtered.groupby(["msrun_id", "msms_id"]).agg(filtered_spec_len=('mz', 'size'))

# implode data into numpy arrays

def _to_list(vals):
    # Would be ideal to use `to_numpy()` here, but this fails
    # with "Must produce aggregated value" error.
    # https://github.com/pandas-dev/pandas/issues/24016
    return vals.to_list()

def aggregate_spectra(
    df,
    mz_column="mz",
    new_mz_column="mzs",
    mz_dtype=np.float32,
    intensity_column="intensity",
    new_intensity_column="intensities",
    intensity_dtype=np.int32,
    groupby=("msrun_id", "msms_id"),
):
    """Returns a new dataframe with numpy arrays for mzs and intensities."""
    one_per_row = df.groupby(list(groupby)).agg(
        **{
            new_mz_column: (mz_column, _to_list),
            new_intensity_column: (intensity_column, _to_list),
        }
    )
    one_per_row[new_mz_column] = one_per_row[new_mz_column].apply(
        np.array, dtype=mz_dtype
    )
    one_per_row[new_intensity_column] = one_per_row[new_intensity_column].apply(
        np.array, dtype=intensity_dtype
    )
    return one_per_row


## How to apply without warning (hint: use assign instead)

If you get a copy on slice, try using assign instead of apply:

# wrong: results in a "set on a copy of a slice" warning:
fractions_with_ms2["active_exclusion"] = fractions_with_ms2.msrun_id.apply(
    lambda msrun_id: active_exclusion_runs[msrun_id]
)

```warning
/tmp/ipykernel_372964/1615522823.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  fractions_with_ms2["active_exclusion"] = fractions_with_ms2.msrun_id.apply(
```
# right: use assign
fractions_with_ms2 = fractions_with_ms2.assign(
    active_exclusion=fractions_with_ms2.msrun_id.apply(
        lambda msrun_id: active_exclusion_runs[msrun_id]
    )
)
